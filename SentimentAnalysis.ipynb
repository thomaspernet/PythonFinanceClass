{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Create connection with Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "### Client is the database\n",
    "db = client['StockTwitClass101']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Pipeline To create Sentiment\n",
    "\n",
    "A) Create a Function to prepare the data\n",
    "    \n",
    "    1. Keep only twit with sentiment either `Bullish` or `Bearish` and remove multiple stock twits\n",
    "   \n",
    "    2. take negation into account, we add the prefix \"negtag_\" to all words following \"not\",\"no\",\"none\",\"neither\",\"never\" or ‚Äúnobody‚Äù\n",
    "    \n",
    "    3. Convert digit to \"_digit\"\n",
    "    \n",
    "    4. Remove when mention a user\n",
    "    \n",
    "    5. lemmatize corpus\n",
    "    \n",
    "    6. Prepare train/test set\n",
    "    \n",
    "B) Build the Vectorization\n",
    "C) Construct the Naive classifier\n",
    "D) Predict out of sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Keep only twit with sentiment either Bullish or Bearish and remove multiple stock twits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(list(db.messages.find(query)))\n",
    "\n",
    "#df['count_stock'] = df['symbols'].apply(lambda x: len(x))\n",
    "\n",
    "#df_toanalyse = df.copy()\n",
    "\n",
    "#df_toanalyse = df_toanalyse[df_toanalyse['count_stock'].isin([1])]\n",
    "\n",
    "#df_toanalyse.shape\n",
    "\n",
    "#df_toanalyse.groupby('sentiment')['sentiment'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Create a Function to prepare the data\n",
    "\n",
    "Step : 1\n",
    "       \n",
    "       - Exclude multi tickers\n",
    "\n",
    "Step : 2\n",
    "       \n",
    "       - take negation into account:\n",
    "       \n",
    "       - \"not\",\"no\",\"none\",\"neither\",\"never\" or ‚Äúnobody‚Äù\n",
    "\n",
    "Step : 3\n",
    "       \n",
    "       - Convert digit to \"_digit\"\n",
    "\n",
    "Step : 4\n",
    "        \n",
    "       - Remove @USER\n",
    "\n",
    "Step : 5\n",
    "       \n",
    "       - Remove unicode issue\n",
    "        \n",
    "Step 6: Lemmanize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def metatransformation(query, to_train = True):\n",
    "    \"\"\"\n",
    "    Step : 1\n",
    "        - Exclude multi tickers\n",
    "\n",
    "    Step : 2\n",
    "        - take negation into account:\n",
    "        - \"not\",\"no\",\"none\",\"neither\",\"never\" or ‚Äúnobody‚Äù\n",
    "\n",
    "    Step : 3\n",
    "        - Convert digit to \"_digit\"\n",
    "\n",
    "    Step : 4\n",
    "        - Remove @USER\n",
    "\n",
    "    Step : 5\n",
    "        - Remove unicode issue\n",
    "        \n",
    "    Step 6: Lemmanize\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    text = pd.DataFrame(list(db.messages.find(query)))\n",
    "    \n",
    "    ### Count stock\n",
    "    \n",
    "    text['count_stock'] = text['symbols'].apply(lambda x: len(x))\n",
    "    \n",
    "    ### Extract single count\n",
    "    \n",
    "    text = text[text['count_stock'].isin([1])]\n",
    "\n",
    "    #text = df.copy()\n",
    "\n",
    "    # take negation into account\n",
    "    text['body_transform'] = text['body'].replace(regex={r\"\\bnothing\\b\": 'nothing_negword',\n",
    "                                                         r\"\\bno\\b\": 'no_negword',\n",
    "                                                         r\"\\bnone\\b\": 'none_negword',\n",
    "                                                         r\"\\bneither\\b\": 'neither_negword',\n",
    "                                                         r\"\\bnever\\b\": 'never_negword',\n",
    "                                                         r\"\\bnobody\\b\": 'nobody_negword'\n",
    "                                                         })\n",
    "\n",
    "    # Convert digit to \"_digit\"\n",
    "\n",
    "    text['body_transform'] = text['body_transform'].replace(regex={r\"\\d+\": 'isDigit'})\n",
    "\n",
    "    ### Remove @USER\n",
    "\n",
    "    text['body_transform'] = text['body_transform'].replace(\n",
    "        regex={r\"([@?])(\\w+)\\b\": 'user'})\n",
    "\n",
    "    # Remove unicode issue\n",
    "\n",
    "    text['body_transform'] = text['body_transform'].replace(regex={r\"\\b&#\\b\": ' '})\n",
    "\n",
    "    # Lemmatize\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "    text['body_transform'] = text['body_transform'].apply(lambda x: ' '.join(\n",
    "        [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(x)]))\n",
    "    \n",
    "    ### Split the dataset \n",
    "\n",
    "    \n",
    "    X_ = text['body_transform']\n",
    "    y_ = text['sentiment_']\n",
    "    \n",
    "    count_ = text.groupby('sentiment')['sentiment'].count()\n",
    "    \n",
    "    print(\"The shape of the data is {}, and {}\".format(text.shape,\n",
    "                                                       count_\n",
    "                                                      ))\n",
    "    \n",
    "    if to_train:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_, y_, \n",
    "                                                        test_size=0.1,\n",
    "                                                        random_state=0)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Pipeline step\n",
    "\n",
    "This step includes:\n",
    "\n",
    "- Build the Vectorization\n",
    "- Construct the Naive classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=1500,\n",
    "                             min_df=10,\n",
    "                             max_df=0.7,\n",
    "                             stop_words=stopwords.words('english'))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Create the first transformation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "query ={\n",
    "    \"sentiment\":{ \"$ne\": \"Neutral\" }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is (40560, 10), and sentiment\n",
      "Bearish    12133\n",
      "Bullish    28427\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = metatransformation(query = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.7,\n",
       "                                 max_features=1500, min_df=10,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\"...\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1,  1,  1,  1,  1, -1,  1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = text_clf.predict(X_train)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.35      0.50      1155\n",
      "           1       0.79      0.97      0.87      2901\n",
      "\n",
      "    accuracy                           0.80      4056\n",
      "   macro avg       0.82      0.66      0.69      4056\n",
      "weighted avg       0.81      0.80      0.77      4056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test,\n",
    "                                    predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 410,  745],\n",
       "       [  73, 2828]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Predict out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is (34697, 10), and sentiment\n",
      "Neutral    34697\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "query ={\n",
    "    \"sentiment\":\"Neutral\" \n",
    "}\n",
    "X_predict = metatransformation(query = query,\n",
    "                               to_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>body</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>$BTC.X all bear get back to your isDigitk job ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>$BTC.X isDigitk!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>$BTC.X sadly look like bitcoin ha a leg down b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>$BTC.X nice fly again.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>$BTC.X</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>$BTC.X if google ha quantum supremacy right no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>$BTC.X Its been so long! But my time ha come o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>$BTC.X Could drop next week judging from the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>$BTC.X everyone know that it‚Äôs going to isDigi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>What isDigit;s interesting to see is that most...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>$BTC.X anyone still think isDigitk by October ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>$BTC.X because most of u are at work. Not real...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>$BTC.X Bulls getting üí©‚Äôposted today</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>$BTC.X Damn I trade both ways, but the bull ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>$BTC.X all bear get back to your isDigitk job ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>$BTC.X isDigitk!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>$BTC.X sadly look like bitcoin ha a leg down b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>$BTC.X nice fly again.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>$BTC.X</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>$BTC.X if google ha quantum supremacy right no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23</td>\n",
       "      <td>$BTC.X Its been so long! But my time ha come o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>$BTC.X Could drop next week judging from the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25</td>\n",
       "      <td>$BTC.X everyone know that it‚Äôs going to isDigi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26</td>\n",
       "      <td>What isDigit;s interesting to see is that most...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27</td>\n",
       "      <td>$BTC.X anyone still think isDigitk by October ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29</td>\n",
       "      <td>$BTC.X because most of u are at work. Not real...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>$BTC.X Bulls getting üí©‚Äôposted today</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>31</td>\n",
       "      <td>$BTC.X Damn I trade both ways, but the bull ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>$BTC.X bear breaking arm to pat themselves on ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>33</td>\n",
       "      <td>$BTC.X Come on back whale come on back</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34667</th>\n",
       "      <td>41094</td>\n",
       "      <td>$BTC.X All triangle broken now!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34668</th>\n",
       "      <td>41095</td>\n",
       "      <td>$BTC.X oh no_negword. sorry dudes. dammit</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34669</th>\n",
       "      <td>41096</td>\n",
       "      <td>$BTC.X holy shit</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34670</th>\n",
       "      <td>41097</td>\n",
       "      <td>$BTC.X holy s#it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34671</th>\n",
       "      <td>41098</td>\n",
       "      <td>$BTC.X A drop to isDigitk would be beautiful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34672</th>\n",
       "      <td>41099</td>\n",
       "      <td>$BTC.X Can we get an F in the chat please</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34673</th>\n",
       "      <td>41100</td>\n",
       "      <td>$BTC.X GLTYA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34674</th>\n",
       "      <td>41101</td>\n",
       "      <td>$BTC.X Store of Value!!!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34675</th>\n",
       "      <td>41102</td>\n",
       "      <td>$BTC.X</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34676</th>\n",
       "      <td>41104</td>\n",
       "      <td>$btc.x u Still up factor versus the spisDigit....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34677</th>\n",
       "      <td>41105</td>\n",
       "      <td>$BTC.X Thanks Bakkt :-)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34678</th>\n",
       "      <td>41106</td>\n",
       "      <td>$BTC.X Bottom is here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34679</th>\n",
       "      <td>41108</td>\n",
       "      <td>$BTC.X üéà</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34680</th>\n",
       "      <td>41109</td>\n",
       "      <td>$BTC.X month in the making</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34681</th>\n",
       "      <td>41110</td>\n",
       "      <td>$BTC.X well I‚Äôm FREEEEEEE... FREE FALLIN!!!!!!!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34682</th>\n",
       "      <td>41111</td>\n",
       "      <td>$BTC.X üéà</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34683</th>\n",
       "      <td>41112</td>\n",
       "      <td>$BTC.X I guess it really couldn isDigit;t brea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34684</th>\n",
       "      <td>41113</td>\n",
       "      <td>$BTC.X lol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34685</th>\n",
       "      <td>41114</td>\n",
       "      <td>$BTC.X üóëüóëüóë</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34686</th>\n",
       "      <td>41115</td>\n",
       "      <td>$BTC.X reminder isDigit and then isDigit üòÇüòÇüòÇüòÇ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34687</th>\n",
       "      <td>41116</td>\n",
       "      <td>$BTC.X How are the alt haha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34688</th>\n",
       "      <td>41117</td>\n",
       "      <td>$BTC.X There go your isDigit month wedge boy a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34689</th>\n",
       "      <td>41118</td>\n",
       "      <td>$BTC.X :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34690</th>\n",
       "      <td>41119</td>\n",
       "      <td>$BTC.X free falling, I should have sold and re...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34691</th>\n",
       "      <td>41120</td>\n",
       "      <td>$BTC.X FINISH HIM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34692</th>\n",
       "      <td>41121</td>\n",
       "      <td>$BTC.X Stops getting smashed and people gettin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34693</th>\n",
       "      <td>41122</td>\n",
       "      <td>$BTC.X Broke support really no_negword telling...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34694</th>\n",
       "      <td>41123</td>\n",
       "      <td>$BTC.X thats a heckuva dip! Buying since i lik...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34695</th>\n",
       "      <td>41124</td>\n",
       "      <td>$BTC.X looking for that gap fill, it seems</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34696</th>\n",
       "      <td>41125</td>\n",
       "      <td>$BTC.X Bears be winning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34697 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               body  predict\n",
       "0          0  $BTC.X all bear get back to your isDigitk job ...        1\n",
       "1          2                                   $BTC.X isDigitk!        1\n",
       "2          3  $BTC.X sadly look like bitcoin ha a leg down b...        1\n",
       "3          4                             $BTC.X nice fly again.        1\n",
       "4          5                                             $BTC.X        1\n",
       "5          6  $BTC.X if google ha quantum supremacy right no...        1\n",
       "6          7  $BTC.X Its been so long! But my time ha come o...        1\n",
       "7          8  $BTC.X Could drop next week judging from the p...        1\n",
       "8          9  $BTC.X everyone know that it‚Äôs going to isDigi...        1\n",
       "9         10  What isDigit;s interesting to see is that most...        1\n",
       "10        11  $BTC.X anyone still think isDigitk by October ...        1\n",
       "11        13  $BTC.X because most of u are at work. Not real...        1\n",
       "12        14                $BTC.X Bulls getting üí©‚Äôposted today        1\n",
       "13        15  $BTC.X Damn I trade both ways, but the bull ar...        1\n",
       "14        16  $BTC.X all bear get back to your isDigitk job ...        1\n",
       "15        18                                   $BTC.X isDigitk!        1\n",
       "16        19  $BTC.X sadly look like bitcoin ha a leg down b...        1\n",
       "17        20                             $BTC.X nice fly again.        1\n",
       "18        21                                             $BTC.X        1\n",
       "19        22  $BTC.X if google ha quantum supremacy right no...        1\n",
       "20        23  $BTC.X Its been so long! But my time ha come o...        1\n",
       "21        24  $BTC.X Could drop next week judging from the p...        1\n",
       "22        25  $BTC.X everyone know that it‚Äôs going to isDigi...        1\n",
       "23        26  What isDigit;s interesting to see is that most...        1\n",
       "24        27  $BTC.X anyone still think isDigitk by October ...        1\n",
       "25        29  $BTC.X because most of u are at work. Not real...        1\n",
       "26        30                $BTC.X Bulls getting üí©‚Äôposted today        1\n",
       "27        31  $BTC.X Damn I trade both ways, but the bull ar...        1\n",
       "28        32  $BTC.X bear breaking arm to pat themselves on ...        1\n",
       "29        33             $BTC.X Come on back whale come on back        1\n",
       "...      ...                                                ...      ...\n",
       "34667  41094                    $BTC.X All triangle broken now!        1\n",
       "34668  41095          $BTC.X oh no_negword. sorry dudes. dammit       -1\n",
       "34669  41096                                   $BTC.X holy shit       -1\n",
       "34670  41097                                   $BTC.X holy s#it        1\n",
       "34671  41098       $BTC.X A drop to isDigitk would be beautiful        1\n",
       "34672  41099          $BTC.X Can we get an F in the chat please        1\n",
       "34673  41100                                       $BTC.X GLTYA        1\n",
       "34674  41101                           $BTC.X Store of Value!!!       -1\n",
       "34675  41102                                             $BTC.X        1\n",
       "34676  41104  $btc.x u Still up factor versus the spisDigit....        1\n",
       "34677  41105                            $BTC.X Thanks Bakkt :-)        1\n",
       "34678  41106                              $BTC.X Bottom is here        1\n",
       "34679  41108                                           $BTC.X üéà        1\n",
       "34680  41109                         $BTC.X month in the making        1\n",
       "34681  41110    $BTC.X well I‚Äôm FREEEEEEE... FREE FALLIN!!!!!!!       -1\n",
       "34682  41111                                           $BTC.X üéà        1\n",
       "34683  41112  $BTC.X I guess it really couldn isDigit;t brea...        1\n",
       "34684  41113                                         $BTC.X lol        1\n",
       "34685  41114                                         $BTC.X üóëüóëüóë        1\n",
       "34686  41115      $BTC.X reminder isDigit and then isDigit üòÇüòÇüòÇüòÇ        1\n",
       "34687  41116                        $BTC.X How are the alt haha        1\n",
       "34688  41117  $BTC.X There go your isDigit month wedge boy a...        1\n",
       "34689  41118                                          $BTC.X :)        1\n",
       "34690  41119  $BTC.X free falling, I should have sold and re...       -1\n",
       "34691  41120                                  $BTC.X FINISH HIM        1\n",
       "34692  41121  $BTC.X Stops getting smashed and people gettin...        1\n",
       "34693  41122  $BTC.X Broke support really no_negword telling...        1\n",
       "34694  41123  $BTC.X thats a heckuva dip! Buying since i lik...       -1\n",
       "34695  41124         $BTC.X looking for that gap fill, it seems        1\n",
       "34696  41125                            $BTC.X Bears be winning        1\n",
       "\n",
       "[34697 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.Series(X_predict, name = 'body').reset_index(),\n",
    "          pd.Series(predicted, name = 'predict')], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for key, value in count_vect.vocabulary_.items():\n",
    "    if i < 5:\n",
    "        print(key, value)\n",
    "    else:\n",
    "        break\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "count_vect.get_feature_names()\n",
    "len(X_train_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.text import FreqDistVisualizer\n",
    "from yellowbrick.datasets import load_hobbies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "features = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "visualizer = FreqDistVisualizer(features=features, orient='v')\n",
    "visualizer.fit(X_train_counts)\n",
    "visualizer.poof()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
